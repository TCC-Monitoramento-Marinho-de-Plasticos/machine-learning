"""
MiniGPT: Implementa√ß√£o de um modelo Transformer simplificado para gera√ß√£o de texto
Vers√£o 2.0 - Corpus Melhorado e Prompts Alinhados

Autor: MR Autoral
Data: 2025
Vers√£o: 2.0.0 - Corpus expandido e prompts contextualizados
"""

import os
import logging
from typing import Optional, Tuple, Dict, Any
from dataclasses import dataclass
from pathlib import Path

import torch
import torch.nn as nn
from torch.nn import functional as F


# ============================================================================
# CONFIGURA√á√ïES E HIPERPAR√ÇMETROS
# ============================================================================

@dataclass
class ModelConfig:
    """Configura√ß√µes do modelo MiniGPT"""
    # Hiperpar√¢metros de treinamento
    batch_size: int = 32
    block_size: int = 64
    max_iters: int = 3000
    eval_interval: int = 300
    learning_rate: float = 3e-4
    eval_iters: int = 200
    
    # Arquitetura do modelo
    n_embd: int = 128
    n_head: int = 8
    n_layer: int = 6
    dropout: float = 0.1
    
    # Configura√ß√µes do sistema
    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'
    seed: int = 1337
    
    # Configura√ß√µes de dados
    train_split: float = 0.9
    input_file: str = 'corpus_tech.txt'


class Logger:
    """Classe para logging estruturado"""
    
    def __init__(self, name: str = "MiniGPT"):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    def info(self, message: str) -> None:
        self.logger.info(message)
    
    def warning(self, message: str) -> None:
        self.logger.warning(message)
    
    def error(self, message: str) -> None:
        self.logger.error(message)


# ============================================================================
# PREPARA√á√ÉO E PROCESSAMENTO DE DADOS
# ============================================================================

class TextDataProcessor:
    """Classe respons√°vel pelo processamento de dados de texto"""
    
    def __init__(self, config: ModelConfig, logger: Logger):
        self.config = config
        self.logger = logger
        self.chars = []
        self.vocab_size = 0
        self.stoi = {}
        self.itos = {}
        self._is_initialized = False
        
    def create_rich_corpus(self) -> None:
        """Cria um corpus rico e extenso sobre tecnologia"""
        corpus_text = """A intelig√™ncia artificial representa uma das maiores revolu√ß√µes tecnol√≥gicas da hist√≥ria humana. Desde os primeiros algoritmos at√© os modernos sistemas de aprendizado profundo, a IA tem transformado nossa sociedade de maneiras inimagin√°veis.

Python √© uma linguagem de programa√ß√£o poderosa e vers√°til que se tornou fundamental no desenvolvimento de aplica√ß√µes de intelig√™ncia artificial. Sua sintaxe clara e bibliotecas robustas como TensorFlow, PyTorch e scikit-learn fazem dela a escolha preferida de cientistas de dados e engenheiros de machine learning.

O futuro da tecnologia est√° intrinsecamente ligado ao avan√ßo da intelig√™ncia artificial. Modelos de linguagem como GPT, BERT e outros transformers est√£o revolucionando o processamento de linguagem natural. Estes sistemas conseguem compreender, gerar e traduzir texto com uma precis√£o impressionante.

Machine learning √© o cora√ß√£o da intelig√™ncia artificial moderna. Algoritmos de aprendizado supervisionado, n√£o supervisionado e por refor√ßo permitem que m√°quinas aprendam padr√µes complexos a partir de dados. Redes neurais profundas, especialmente arquiteturas como transformers, t√™m mostrado capacidades extraordin√°rias em tarefas como reconhecimento de imagem, processamento de linguagem natural e gera√ß√£o de conte√∫do.

A ci√™ncia da computa√ß√£o evoluiu dramaticamente nas √∫ltimas d√©cadas. Estruturas de dados eficientes, algoritmos otimizados e arquiteturas de sistemas distribu√≠dos s√£o fundamentais para lidar com o volume massivo de dados da era digital. Conceitos como big data, cloud computing e edge computing definem o panorama tecnol√≥gico atual.

Deep learning utiliza redes neurais com m√∫ltiplas camadas para modelar e compreender dados complexos. T√©cnicas como convolu√ß√£o, aten√ß√£o e normaliza√ß√£o por lotes t√™m permitido avan√ßos significativos em vis√£o computacional, processamento de linguagem natural e outras √°reas da intelig√™ncia artificial.

Transformers revolucionaram o campo do processamento de linguagem natural. O mecanismo de aten√ß√£o permite que estes modelos capturem depend√™ncias de longo alcance em sequ√™ncias, resultando em melhor compreens√£o contextual. Modelos como GPT, BERT e T5 demonstram o poder desta arquitetura.

A programa√ß√£o em Python oferece uma sintaxe intuitiva e uma vasta gama de bibliotecas especializadas. NumPy para computa√ß√£o num√©rica, Pandas para manipula√ß√£o de dados, Matplotlib para visualiza√ß√£o e Jupyter Notebooks para desenvolvimento interativo formam um ecossistema poderoso para ci√™ncia de dados.

Algoritmos de otimiza√ß√£o como gradiente descendente, Adam e RMSprop s√£o essenciais para treinar modelos de machine learning. A retropropaga√ß√£o permite que redes neurais ajustem seus pesos de forma eficiente, enquanto t√©cnicas de regulariza√ß√£o como dropout e normaliza√ß√£o por lotes previnem overfitting.

O processamento de linguagem natural combina lingu√≠stica computacional com machine learning para permitir que computadores compreendam e gerem linguagem humana. Tarefas como an√°lise de sentimento, tradu√ß√£o autom√°tica, sumariza√ß√£o de texto e gera√ß√£o de conte√∫do s√£o aplica√ß√µes pr√°ticas desta √°rea.

Redes neurais artificiais s√£o inspiradas no funcionamento do c√©rebro humano. Neur√¥nios artificiais processam informa√ß√µes atrav√©s de fun√ß√µes de ativa√ß√£o como ReLU, sigmoid e tanh. Arquiteturas como redes convolucionais, recorrentes e transformers s√£o especializadas para diferentes tipos de dados e tarefas.

A era dos dados massivos exige ferramentas e t√©cnicas especializadas. Hadoop, Spark e outras tecnologias de big data permitem processar volumes enormes de informa√ß√£o. Bancos de dados NoSQL como MongoDB e Cassandra oferecem flexibilidade para dados n√£o estruturados.

Aprendizado por refor√ßo permite que agentes artificiais aprendam atrav√©s da intera√ß√£o com ambientes. Algoritmos como Q-learning, policy gradients e actor-critic t√™m sido aplicados com sucesso em jogos, rob√≥tica e sistemas de recomenda√ß√£o.

A vis√£o computacional utiliza t√©cnicas de deep learning para interpretar e analisar imagens e v√≠deos. Redes neurais convolucionais s√£o particularmente eficazes para reconhecimento de objetos, detec√ß√£o facial e segmenta√ß√£o de imagens.

Sistemas distribu√≠dos s√£o fundamentais para aplica√ß√µes modernas de grande escala. Conceitos como microservi√ßos, containeriza√ß√£o com Docker e orquestra√ß√£o com Kubernetes permitem construir aplica√ß√µes robustas e escal√°veis.

A seguran√ßa cibern√©tica torna-se cada vez mais cr√≠tica √† medida que nossa depend√™ncia da tecnologia aumenta. Criptografia, autentica√ß√£o multifator e detec√ß√£o de anomalias baseada em machine learning s√£o componentes essenciais da prote√ß√£o digital.

Computa√ß√£o qu√¢ntica representa a pr√≥xima fronteira da computa√ß√£o. Qubits, superposi√ß√£o e emaranhamento qu√¢ntico prometem resolver problemas computacionalmente intrat√°veis para computadores cl√°ssicos.

A √©tica em intelig√™ncia artificial √© uma preocupa√ß√£o crescente. Quest√µes sobre vi√©s algor√≠tmico, privacidade de dados, transpar√™ncia de modelos e impacto social da automa√ß√£o requerem considera√ß√£o cuidadosa no desenvolvimento de sistemas de IA.

DevOps integra desenvolvimento e opera√ß√µes para acelerar a entrega de software. Pr√°ticas como integra√ß√£o cont√≠nua, entrega cont√≠nua e infraestrutura como c√≥digo s√£o essenciais para equipes de desenvolvimento modernas.

A internet das coisas conecta dispositivos f√≠sicos √† internet, gerando volumes massivos de dados. Sensores, atuadores e sistemas embarcados criam uma rede ub√≠qua de dispositivos inteligentes.

Blockchain e tecnologias de ledger distribu√≠do oferecem novas possibilidades para sistemas descentralizados. Contratos inteligentes, criptomoedas e aplica√ß√µes descentralizadas representam inova√ß√µes significativas em sistemas distribu√≠dos.

A realidade aumentada e virtual est√£o transformando como interagimos com informa√ß√£o digital. Tecnologias imersivas t√™m aplica√ß√µes em educa√ß√£o, entretenimento, treinamento e visualiza√ß√£o de dados.

Computa√ß√£o em nuvem democratizou o acesso a recursos computacionais poderosos. Servi√ßos como AWS, Azure e Google Cloud Platform oferecem infraestrutura escal√°vel para aplica√ß√µes de qualquer tamanho.

A an√°lise de dados revela insights valiosos escondidos em grandes conjuntos de dados. T√©cnicas estat√≠sticas, visualiza√ß√£o de dados e machine learning trabalham juntas para extrair conhecimento acion√°vel.

Arquiteturas de software modernas enfatizam modularidade, escalabilidade e manutenibilidade. Padr√µes de design, princ√≠pios SOLID e arquiteturas hexagonais guiam o desenvolvimento de sistemas robustos.

A automa√ß√£o est√° transformando ind√∫strias inteiras. Rob√≥tica, sistemas aut√¥nomos e processos automatizados aumentam efici√™ncia e reduzem custos operacionais.

Interfaces de usu√°rio intuitivas s√£o cruciais para a ado√ß√£o de tecnologia. Design centrado no usu√°rio, experi√™ncia do usu√°rio e acessibilidade garantem que sistemas complexos sejam utiliz√°veis por todos.

A computa√ß√£o de borda traz processamento mais pr√≥ximo dos dados, reduzindo lat√™ncia e melhorando performance. Edge computing √© especialmente importante para aplica√ß√µes em tempo real e IoT.

Sistemas de recomenda√ß√£o utilizam machine learning para personalizar experi√™ncias. Filtragem colaborativa, filtragem baseada em conte√∫do e deep learning criam recomenda√ß√µes relevantes para usu√°rios.

A ci√™ncia de dados combina estat√≠stica, programa√ß√£o e conhecimento de dom√≠nio para extrair insights de dados. O processo de descoberta de conhecimento em dados envolve coleta, limpeza, an√°lise e interpreta√ß√£o.

Tecnologias emergentes como computa√ß√£o neurom√≥rfica, computa√ß√£o DNA e computa√ß√£o √≥ptica prometem revolucionar a computa√ß√£o nas pr√≥ximas d√©cadas.

A colabora√ß√£o entre humanos e intelig√™ncia artificial est√° criando novas possibilidades. Sistemas de IA aumentam capacidades humanas em vez de simplesmente substitu√≠-las, criando parcerias produtivas.

O desenvolvimento sustent√°vel de tecnologia considera impacto ambiental e social. Green computing, efici√™ncia energ√©tica e responsabilidade social corporativa s√£o considera√ß√µes importantes no desenvolvimento tecnol√≥gico.

A educa√ß√£o em tecnologia deve evoluir para preparar profissionais para o futuro digital. Pensamento computacional, alfabetiza√ß√£o em dados e habilidades de programa√ß√£o tornam-se fundamentais para todas as profiss√µes.

A pesquisa em intelig√™ncia artificial continua avan√ßando rapidamente. Novos algoritmos, arquiteturas e t√©cnicas s√£o desenvolvidos constantemente, empurrando os limites do que √© poss√≠vel com sistemas artificiais.

A interdisciplinaridade √© essencial na tecnologia moderna. Colabora√ß√£o entre cientistas da computa√ß√£o, matem√°ticos, psic√≥logos, linguistas e especialistas de dom√≠nio resulta em solu√ß√µes mais robustas e inovadoras.

O futuro da humanidade est√° intimamente ligado ao desenvolvimento respons√°vel da tecnologia. Equilibrar inova√ß√£o com considera√ß√µes √©ticas, sociais e ambientais √© crucial para um futuro sustent√°vel e pr√≥spero."""

        with open(self.config.input_file, 'w', encoding='utf-8') as f:
            f.write(corpus_text)
        
        self.logger.info(f"Corpus rico criado: '{self.config.input_file}' ({len(corpus_text)} caracteres)")
    
    def _build_vocabulary(self, text: str) -> None:
        """Constr√≥i o vocabul√°rio a partir do texto"""
        # Cria vocabul√°rio
        self.chars = sorted(list(set(text)))
        self.vocab_size = len(self.chars)
        
        # Cria mapeamentos
        self.stoi = {ch: i for i, ch in enumerate(self.chars)}
        self.itos = {i: ch for i, ch in enumerate(self.chars)}
        
        self._is_initialized = True
        self.logger.info(f"Vocabul√°rio criado com {self.vocab_size} caracteres √∫nicos")
        self.logger.info(f"Amostra do vocabul√°rio: {''.join(self.chars[:30])}{'...' if len(self.chars) > 30 else ''}")
    
    def load_and_process_data(self) -> Tuple[torch.Tensor, torch.Tensor]:
        """Carrega e processa os dados de texto"""
        # Verifica se o arquivo existe, sen√£o cria um corpus rico
        if not Path(self.config.input_file).exists():
            self.logger.warning(f"Arquivo '{self.config.input_file}' n√£o encontrado")
            self.create_rich_corpus()
        
        # Carrega o texto
        try:
            with open(self.config.input_file, 'r', encoding='utf-8') as f:
                text = f.read()
        except Exception as e:
            self.logger.error(f"Erro ao carregar arquivo: {e}")
            raise
        
        if not text.strip():
            raise ValueError("Arquivo de texto est√° vazio")
        
        self.logger.info(f"Texto carregado: {len(text)} caracteres")
        
        # Constr√≥i vocabul√°rio
        self._build_vocabulary(text)
        
        # Tokeniza o texto
        try:
            data = torch.tensor(self.encode(text), dtype=torch.long)
        except Exception as e:
            self.logger.error(f"Erro na tokeniza√ß√£o: {e}")
            raise
        
        # Divide em treino e valida√ß√£o
        n = int(self.config.train_split * len(data))
        train_data = data[:n]
        val_data = data[n:]
        
        self.logger.info(f"Dados divididos: {len(train_data)} treino, {len(val_data)} valida√ß√£o")
        
        return train_data, val_data
    
    def encode(self, text: str) -> list:
        """Codifica texto em lista de inteiros"""
        if not self._is_initialized:
            raise RuntimeError("Vocabul√°rio n√£o foi inicializado. Chame load_and_process_data() primeiro.")
        
        try:
            return [self.stoi[c] for c in text]
        except KeyError as e:
            missing_char = str(e).strip("'")
            self.logger.error(f"Caractere '{missing_char}' n√£o encontrado no vocabul√°rio")
            # Filtra caracteres desconhecidos
            return [self.stoi[c] for c in text if c in self.stoi]
    
    def decode(self, tokens: list) -> str:
        """Decodifica lista de inteiros em texto"""
        if not self._is_initialized:
            raise RuntimeError("Vocabul√°rio n√£o foi inicializado. Chame load_and_process_data() primeiro.")
        
        try:
            return ''.join([self.itos[i] for i in tokens])
        except KeyError as e:
            self.logger.error(f"Token {e} n√£o encontrado no vocabul√°rio")
            # Filtra tokens desconhecidos
            return ''.join([self.itos[i] for i in tokens if i in self.itos])


class DataLoader:
    """Classe para carregamento de lotes de dados"""
    
    def __init__(self, train_data: torch.Tensor, val_data: torch.Tensor, 
                 config: ModelConfig):
        self.train_data = train_data
        self.val_data = val_data
        self.config = config
        
        # Valida√ß√µes
        if len(train_data) < config.block_size:
            raise ValueError(f"Dados de treino muito pequenos: {len(train_data)} < {config.block_size}")
        if len(val_data) < config.block_size:
            raise ValueError(f"Dados de valida√ß√£o muito pequenos: {len(val_data)} < {config.block_size}")
    
    def get_batch(self, split: str) -> Tuple[torch.Tensor, torch.Tensor]:
        """Carrega um lote de dados"""
        data = self.train_data if split == 'train' else self.val_data
        
        # Garante que temos dados suficientes
        max_start_idx = len(data) - self.config.block_size
        if max_start_idx <= 0:
            raise ValueError(f"Dados insuficientes para block_size {self.config.block_size}")
        
        ix = torch.randint(max_start_idx, (self.config.batch_size,))
        x = torch.stack([data[i:i+self.config.block_size] for i in ix])
        y = torch.stack([data[i+1:i+self.config.block_size+1] for i in ix])
        
        x, y = x.to(self.config.device), y.to(self.config.device)
        return x, y


# ============================================================================
# COMPONENTES DO MODELO TRANSFORMER
# ============================================================================

class AttentionHead(nn.Module):
    """Uma √∫nica cabe√ßa do mecanismo de autoaten√ß√£o"""
    
    def __init__(self, config: ModelConfig, head_size: int):
        super().__init__()
        self.head_size = head_size
        self.config = config
        
        self.key = nn.Linear(config.n_embd, head_size, bias=False)
        self.query = nn.Linear(config.n_embd, head_size, bias=False)
        self.value = nn.Linear(config.n_embd, head_size, bias=False)
        
        self.register_buffer(
            'tril', 
            torch.tril(torch.ones(config.block_size, config.block_size))
        )
        self.dropout = nn.Dropout(config.dropout)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, T, C = x.shape
        
        k = self.key(x)
        q = self.query(x)
        v = self.value(x)
        
        # Calcula scores de aten√ß√£o
        wei = q @ k.transpose(-2, -1) * (self.head_size ** -0.5)
        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))
        wei = F.softmax(wei, dim=-1)
        wei = self.dropout(wei)
        
        # Agrega√ß√£o ponderada
        out = wei @ v
        return out


class MultiHeadAttention(nn.Module):
    """M√∫ltiplas cabe√ßas de autoaten√ß√£o em paralelo"""
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        head_size = config.n_embd // config.n_head
        
        self.heads = nn.ModuleList([
            AttentionHead(config, head_size) for _ in range(config.n_head)
        ])
        self.proj = nn.Linear(config.n_embd, config.n_embd)
        self.dropout = nn.Dropout(config.dropout)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        out = torch.cat([h(x) for h in self.heads], dim=-1)
        out = self.dropout(self.proj(out))
        return out


class FeedForward(nn.Module):
    """Rede feed-forward"""
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(config.n_embd, 4 * config.n_embd),
            nn.GELU(),
            nn.Linear(4 * config.n_embd, config.n_embd),
            nn.Dropout(config.dropout),
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)


class TransformerBlock(nn.Module):
    """Bloco Transformer completo"""
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.sa = MultiHeadAttention(config)
        self.ffwd = FeedForward(config)
        self.ln1 = nn.LayerNorm(config.n_embd)
        self.ln2 = nn.LayerNorm(config.n_embd)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = x + self.sa(self.ln1(x))
        x = x + self.ffwd(self.ln2(x))
        return x


# ============================================================================
# MODELO PRINCIPAL
# ============================================================================

class MiniGPT(nn.Module):
    """Modelo MiniGPT completo"""
    
    def __init__(self, config: ModelConfig, vocab_size: int):
        super().__init__()
        self.config = config
        self.vocab_size = vocab_size
        
        self.token_embedding_table = nn.Embedding(vocab_size, config.n_embd)
        self.position_embedding_table = nn.Embedding(config.block_size, config.n_embd)
        
        self.blocks = nn.Sequential(*[
            TransformerBlock(config) for _ in range(config.n_layer)
        ])
        
        self.ln_f = nn.LayerNorm(config.n_embd)
        self.lm_head = nn.Linear(config.n_embd, vocab_size)
        
        # Inicializa√ß√£o de pesos
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        """Inicializa√ß√£o de pesos do modelo"""
        if isinstance(module, nn.Linear):
            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
    
    def forward(self, idx: torch.Tensor, targets: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        B, T = idx.shape
        
        # Valida√ß√£o de entrada
        if T > self.config.block_size:
            raise ValueError(f"Sequ√™ncia muito longa: {T} > {self.config.block_size}")
        
        tok_emb = self.token_embedding_table(idx)
        pos_emb = self.position_embedding_table(torch.arange(T, device=self.config.device))
        
        x = tok_emb + pos_emb
        x = self.blocks(x)
        x = self.ln_f(x)
        logits = self.lm_head(x)
        
        loss = None
        if targets is not None:
            B, T, C = logits.shape
            logits_flat = logits.view(B*T, C)
            targets_flat = targets.view(B*T)
            loss = F.cross_entropy(logits_flat, targets_flat)
        
        return logits, loss
    
    def generate(self, idx: torch.Tensor, max_new_tokens: int, temperature: float = 1.0) -> torch.Tensor:
        """Gera novos tokens de forma autoregressiva com controle de temperatura"""
        self.eval()
        
        with torch.no_grad():
            for _ in range(max_new_tokens):
                # Limita o contexto ao tamanho m√°ximo
                idx_cond = idx[:, -self.config.block_size:]
                logits, _ = self(idx_cond)
                logits = logits[:, -1, :] / temperature
                probs = F.softmax(logits, dim=-1)
                idx_next = torch.multinomial(probs, num_samples=1)
                idx = torch.cat((idx, idx_next), dim=1)
        
        self.train()
        return idx
    
    def count_parameters(self) -> int:
        """Conta o n√∫mero total de par√¢metros"""
        return sum(p.numel() for p in self.parameters())


# ============================================================================
# TREINADOR DO MODELO
# ============================================================================

class ModelTrainer:
    """Classe respons√°vel pelo treinamento do modelo"""
    
    def __init__(self, model: MiniGPT, data_loader: DataLoader, 
                 config: ModelConfig, logger: Logger):
        self.model = model
        self.data_loader = data_loader
        self.config = config
        self.logger = logger
        
        self.optimizer = torch.optim.AdamW(
            model.parameters(), 
            lr=config.learning_rate
        )
        
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'iterations': []
        }
    
    @torch.no_grad()
    def estimate_loss(self) -> Dict[str, float]:
        """Estima a perda nos conjuntos de treino e valida√ß√£o"""
        out = {}
        self.model.eval()
        
        for split in ['train', 'val']:
            losses = torch.zeros(self.config.eval_iters)
            for k in range(self.config.eval_iters):
                try:
                    X, Y = self.data_loader.get_batch(split)
                    logits, loss = self.model(X, Y)
                    losses[k] = loss.item()
                except Exception as e:
                    self.logger.error(f"Erro na avalia√ß√£o: {e}")
                    losses[k] = float('inf')
            out[split] = losses.mean().item()
        
        self.model.train()
        return out
    
    def train(self) -> Dict[str, Any]:
        """Executa o treinamento do modelo"""
        self.logger.info("Iniciando treinamento...")
        self.logger.info(f"Par√¢metros do modelo: {self.model.count_parameters()/1e6:.2f}M")
        self.logger.info(f"Dispositivo: {self.config.device}")
        
        try:
            for iter_num in range(self.config.max_iters):
                # Avalia√ß√£o peri√≥dica
                if iter_num % self.config.eval_interval == 0 or iter_num == self.config.max_iters - 1:
                    losses = self.estimate_loss()
                    self.logger.info(
                        f"Itera√ß√£o {iter_num}: "
                        f"perda treino {losses['train']:.4f}, "
                        f"perda valida√ß√£o {losses['val']:.4f}"
                    )
                    
                    # Salva hist√≥rico
                    self.training_history['train_loss'].append(losses['train'])
                    self.training_history['val_loss'].append(losses['val'])
                    self.training_history['iterations'].append(iter_num)
                
                # Passo de treinamento
                try:
                    xb, yb = self.data_loader.get_batch('train')
                    logits, loss = self.model(xb, yb)
                    
                    self.optimizer.zero_grad(set_to_none=True)
                    loss.backward()
                    self.optimizer.step()
                    
                except Exception as e:
                    self.logger.error(f"Erro no passo de treinamento {iter_num}: {e}")
                    continue
            
            self.logger.info("Treinamento conclu√≠do!")
            
        except KeyboardInterrupt:
            self.logger.info("Treinamento interrompido pelo usu√°rio")
        except Exception as e:
            self.logger.error(f"Erro durante o treinamento: {e}")
            raise
        
        return self.training_history


# ============================================================================
# GERADOR DE TEXTO
# ============================================================================

class TextGenerator:
    """Classe para gera√ß√£o de texto"""
    
    def __init__(self, model: MiniGPT, processor: TextDataProcessor, 
                 config: ModelConfig, logger: Logger):
        self.model = model
        self.processor = processor
        self.config = config
        self.logger = logger
    
    def generate_text(self, prompt: str, max_new_tokens: int = 300, temperature: float = 0.8) -> str:
        """Gera texto a partir de um prompt"""
        if not prompt:
            prompt = "A"  # Prompt m√≠nimo
        
        self.logger.info(f"Gerando texto com prompt: '{prompt[:50]}{'...' if len(prompt) > 50 else ''}'")
        
        try:
            # Codifica o prompt
            encoded_prompt = self.processor.encode(prompt)
            if not encoded_prompt:
                self.logger.warning("Prompt vazio ap√≥s codifica√ß√£o, usando 'A'")
                encoded_prompt = self.processor.encode("A")
            
            context = torch.tensor(
                [encoded_prompt], 
                dtype=torch.long, 
                device=self.config.device
            )
            
            # Gera tokens
            generated_tokens = self.model.generate(
                context, 
                max_new_tokens, 
                temperature=temperature
            )[0].tolist()
            
            # Decodifica para texto
            generated_text = self.processor.decode(generated_tokens)
            
            return generated_text
            
        except Exception as e:
            self.logger.error(f"Erro na gera√ß√£o de texto: {e}")
            return f"Erro na gera√ß√£o: {str(e)}"


# ============================================================================
# FUN√á√ÉO PRINCIPAL
# ============================================================================

def main():
    """Fun√ß√£o principal para execu√ß√£o do MiniGPT"""
    try:
        # Configura√ß√£o
        config = ModelConfig()
        logger = Logger()
        
        logger.info("üöÄ Iniciando MiniGPT v2.0...")
        logger.info(f"Configura√ß√µes: batch_size={config.batch_size}, block_size={config.block_size}")
        
        # Configura√ß√£o de reprodutibilidade
        torch.manual_seed(config.seed)
        
        # Processamento de dados
        logger.info("üìö Carregando e processando dados...")
        processor = TextDataProcessor(config, logger)
        train_data, val_data = processor.load_and_process_data()
        data_loader = DataLoader(train_data, val_data, config)
        
        # Cria√ß√£o do modelo
        logger.info("üß† Criando modelo...")
        model = MiniGPT(config, processor.vocab_size)
        model = model.to(config.device)
        
        # Treinamento
        logger.info("üéØ Iniciando treinamento...")
        trainer = ModelTrainer(model, data_loader, config, logger)
        training_history = trainer.train()
        
        # Gera√ß√£o de texto
        generator = TextGenerator(model, processor, config, logger)
        
        # Prompts alinhados com o corpus de treinamento
        prompts = [
            "artificial",
            "Python  linguagem",
            "tecnologia",
            "Machine learning",
            "Deep learning",
            "Transformers",
            "computa√ß√£o",
            "otimiza√ß√£o"
        ]
        
        logger.info("\nüé® === EXEMPLOS DE GERA√á√ÉO DE TEXTO ===")
        for i, prompt in enumerate(prompts, 1):
            try:
                generated_text = generator.generate_text(
                    prompt, 
                    max_new_tokens=200, 
                    temperature=0.8
                )
                
                print(f"\n{'='*80}")
                print(f"üìù EXEMPLO {i}/8")
                print(f"{'='*80}")
                print(f"üî§ Prompt: '{prompt}'")
                print(f"{'‚îÄ'*80}")
                print(f"ü§ñ Texto Gerado:")
                print(generated_text)
                print(f"{'='*80}")
                
            except Exception as e:
                logger.error(f"Erro ao gerar texto para prompt '{prompt}': {e}")
        
        # Estat√≠sticas finais
        final_train_loss = training_history['train_loss'][-1] if training_history['train_loss'] else 'N/A'
        final_val_loss = training_history['val_loss'][-1] if training_history['val_loss'] else 'N/A'
        
        logger.info(f"\nüìä === ESTAT√çSTICAS FINAIS ===")
        logger.info(f"‚úÖ Treinamento conclu√≠do com sucesso!")
        logger.info(f"üìà Perda final de treino: {final_train_loss}")
        logger.info(f"üìâ Perda final de valida√ß√£o: {final_val_loss}")
        logger.info(f"üî¢ Par√¢metros do modelo: {model.count_parameters()/1e6:.2f}M")
        logger.info(f"üìñ Tamanho do vocabul√°rio: {processor.vocab_size}")
        
    except Exception as e:
        print(f"‚ùå Erro fatal: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()